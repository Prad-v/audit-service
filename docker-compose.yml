version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: audit-postgres
    environment:
      POSTGRES_DB: audit_logs
      POSTGRES_USER: audit_user
      POSTGRES_PASSWORD: audit_password
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U audit_user -d audit_logs"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - audit-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: audit-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - audit-network

  # NATS Message Broker
  nats:
    image: nats:2.10-alpine
    container_name: audit-nats
    ports:
      - "4222:4222"  # Client connections
      - "8222:8222"  # HTTP monitoring
      - "6222:6222"  # Routing port for clustering
    command:
      - "--jetstream"
      - "--store_dir=/data"
      - "--http_port=8222"
    volumes:
      - nats_data:/data
      - ./config/nats.conf:/etc/nats/nats.conf
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - audit-network

  # FastAPI Backend
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: audit-api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://audit_user:audit_password@postgres:5432/audit_logs
      - REDIS_URL=redis://redis:6379/0
      - NATS_URL=nats://nats:4222
      - LOG_LEVEL=INFO
      - ENVIRONMENT=development
    volumes:
      - ./backend:/app
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - audit-network
    restart: unless-stopped

  # Background Worker
  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: audit-worker
    command: python -m app.worker
    environment:
      - DATABASE_URL=postgresql+asyncpg://audit_user:audit_password@postgres:5432/audit_logs
      - REDIS_URL=redis://redis:6379/0
      - NATS_URL=nats://nats:4222
      - LOG_LEVEL=INFO
      - ENVIRONMENT=development
      - WORKER_CONCURRENCY=4
    volumes:
      - ./backend:/app
      - ./logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    networks:
      - audit-network
    restart: unless-stopped

  # Backstage Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: audit-frontend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - BACKEND_URL=http://api:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - api
    networks:
      - audit-network
    restart: unless-stopped

  # # Prometheus Monitoring
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: audit-prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
  #     - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml
  #     - prometheus_data:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #     - '--storage.tsdb.path=/prometheus'
  #     - '--web.console.libraries=/etc/prometheus/console_libraries'
  #     - '--web.console.templates=/etc/prometheus/consoles'
  #     - '--storage.tsdb.retention.time=30d'
  #     - '--web.enable-lifecycle'
  #     - '--web.enable-admin-api'
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

  # # Grafana Dashboard
  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: audit-grafana
  #   ports:
  #     - "3001:3000"
  #   environment:
  #     - GF_SECURITY_ADMIN_USER=admin
  #     - GF_SECURITY_ADMIN_PASSWORD=admin123
  #     - GF_USERS_ALLOW_SIGN_UP=false
  #     - GF_INSTALL_PLUGINS=grafana-piechart-panel
  #   volumes:
  #     - ./monitoring/grafana/grafana.ini:/etc/grafana/grafana.ini
  #     - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
  #     - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
  #     - grafana_data:/var/lib/grafana
  #   depends_on:
  #     - prometheus
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

  # # Node Exporter for system metrics
  # node-exporter:
  #   image: prom/node-exporter:latest
  #   container_name: audit-node-exporter
  #   ports:
  #     - "9100:9100"
  #   volumes:
  #     - /proc:/host/proc:ro
  #     - /sys:/host/sys:ro
  #     - /:/rootfs:ro
  #   command:
  #     - '--path.procfs=/host/proc'
  #     - '--path.rootfs=/rootfs'
  #     - '--path.sysfs=/host/sys'
  #     - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

  # # PostgreSQL Exporter
  # postgres-exporter:
  #   image: prometheuscommunity/postgres-exporter:latest
  #   container_name: audit-postgres-exporter
  #   ports:
  #     - "9187:9187"
  #   environment:
  #     - DATA_SOURCE_NAME=postgresql://audit_user:audit_password@postgres:5432/audit_logs?sslmode=disable
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

  # # Redis Exporter
  # redis-exporter:
  #   image: oliver006/redis_exporter:latest
  #   container_name: audit-redis-exporter
  #   ports:
  #     - "9121:9121"
  #   environment:
  #     - REDIS_ADDR=redis://redis:6379
  #   depends_on:
  #     redis:
  #       condition: service_healthy
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

  # # NATS Exporter
  # nats-exporter:
  #   image: natsio/prometheus-nats-exporter:latest
  #   container_name: audit-nats-exporter
  #   ports:
  #     - "7777:7777"
  #   command:
  #     - '-varz'
  #     - '-connz'
  #     - '-routez'
  #     - '-subz'
  #     - '-serverz'
  #     - 'http://nats:8222'
  #   depends_on:
  #     nats:
  #       condition: service_healthy
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

  # # cAdvisor for container metrics
  # cadvisor:
  #   image: gcr.io/cadvisor/cadvisor:latest
  #   container_name: audit-cadvisor
  #   ports:
  #     - "8080:8080"
  #   volumes:
  #     - /:/rootfs:ro
  #     - /var/run:/var/run:ro
  #     - /sys:/sys:ro
  #     - /var/lib/docker/:/var/lib/docker:ro
  #     - /dev/disk/:/dev/disk:ro
  #   privileged: true
  #   devices:
  #     - /dev/kmsg
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

  # # AlertManager for alert handling
  # alertmanager:
  #   image: prom/alertmanager:latest
  #   container_name: audit-alertmanager
  #   ports:
  #     - "9093:9093"
  #   volumes:
  #     - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
  #     - alertmanager_data:/alertmanager
  #   command:
  #     - '--config.file=/etc/alertmanager/alertmanager.yml'
  #     - '--storage.path=/alertmanager'
  #     - '--web.external-url=http://localhost:9093'
  #   networks:
  #     - audit-network
  #   restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  nats_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  alertmanager_data:
    driver: local

networks:
  audit-network:
    driver: bridge
    ipam:
      config:
        - subnet: 10.10.0.0/16